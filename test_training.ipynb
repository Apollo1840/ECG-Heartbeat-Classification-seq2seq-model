{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq_seq_annot_DS1DS2 import read_mitbih, demonstrate_classes_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/s2s_mitbih_aami_DS1DS2'\n",
    "max_time = 10\n",
    "classes = [\"N\", \"S\", \"V\"]\n",
    "n_oversampling = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records processed!\n",
      "Records processed!\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = read_mitbih(DATA_DIR, max_time, classes=classes, max_nlabel=50000, trainset=1)\n",
    "X_test, y_test = read_mitbih(DATA_DIR, max_time, classes=classes, max_nlabel=50000, trainset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5052, 10, 280)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4924, 10, 280)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNNNNNNNNN', 'NNSSSSSSSS', 'SSSSSSSSSS', 'SSSSSSSSVV',\n",
       "       'VVVVVVVVVV'], dtype='<U10')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([\"\".join(y) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S' 'S']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V' 'V']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']\n",
      " ['N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N' 'N']]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (training):  ['N' 'S' 'V']\n",
      "N 45796\n",
      "S 941\n",
      "V 3773\n",
      "Classes (test):  ['N' 'S' 'V']\n",
      "N 44192\n",
      "S 1836\n",
      "V 3212\n"
     ]
    }
   ],
   "source": [
    "demonstrate_classes_distribution(y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2numY = dict(zip(classes, range(len(classes))))\n",
    "# char2numY = {'N': 0, 'S': 1, 'V': 2}\n",
    "\n",
    "char2numY['<GO>'] = len(char2numY)\n",
    "\n",
    "num2charY = dict(zip(char2numY.values(), char2numY.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 0, 'S': 1, 'V': 2, '<GO>': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char2numY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'N', 1: 'S', 2: 'V', 3: '<GO>'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num2charY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerize_y(y_train, y_test, char2numY):\n",
    "    y_train = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in y_train]\n",
    "    y_test = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in y_test]\n",
    "    y_test = np.asarray(y_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    return y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = numerize_y(y_train, y_test, char2numY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5051, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4924, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in the training set:  [0 1 2 3]\n",
      "0 45796\n",
      "1 7000\n",
      "2 5994\n",
      "3 5879\n",
      "------------------y_train samples--------------------\n",
      "<GO>NNNNNNNNNN\n",
      "<GO>NNNNNNNNNN\n",
      "Classes in the training set:  [0 1 2 3]\n",
      "0 44192\n",
      "1 1836\n",
      "2 3212\n",
      "3 4924\n",
      "------------------y_test samples--------------------\n",
      "<GO>NNNNNNNNNN\n",
      "<GO>NNNNNNNNNN\n"
     ]
    }
   ],
   "source": [
    "# over-sampling: SMOTE\n",
    "X_train = np.reshape(X_train, [X_train.shape[0] * X_train.shape[1], -1])\n",
    "y_train = y_train[:, 1:].flatten()\n",
    "\n",
    "nums = []\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    nums.append(len(np.where(y_train.flatten() == ind)[0]))\n",
    "\n",
    "# ratio={0:nums[0],1:nums[0],2:nums[0]}\n",
    "# ratio={0:7000,1:nums[1],2:7000,3:7000}\n",
    "ratio = {0: nums[0], 1: n_oversampling + 1000, 2: n_oversampling}\n",
    "\n",
    "sm = SMOTE(random_state=12, sampling_strategy=ratio)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "X_train = X_train[:(X_train.shape[0] // max_time) * max_time, :]\n",
    "y_train = y_train[:(X_train.shape[0] // max_time) * max_time]\n",
    "\n",
    "X_train = np.reshape(X_train, [-1, X_test.shape[1], X_test.shape[2]])\n",
    "y_train = np.reshape(y_train, [-1, y_test.shape[1] - 1, ])\n",
    "y_train = [[char2numY['<GO>']] + [y_ for y_ in date] for date in y_train]\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print('Classes in the training set: ', classes)\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    print(cl, len(np.where(y_train.flatten() == ind)[0]))\n",
    "print(\"------------------y_train samples--------------------\")\n",
    "for ii in range(2):\n",
    "    print(''.join([num2charY[y_] for y_ in list(y_train[ii + 5])]))\n",
    "\n",
    "print('Classes in the training set: ', classes)\n",
    "for cl in classes:\n",
    "    ind = np.where(classes == cl)[0][0]\n",
    "    print(cl, len(np.where(y_test.flatten() == ind)[0]))\n",
    "\n",
    "print(\"------------------y_test samples--------------------\")\n",
    "for ii in range(2):\n",
    "    print(''.join([num2charY[y_] for y_ in list(y_test[ii + 5])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5879, 11)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
